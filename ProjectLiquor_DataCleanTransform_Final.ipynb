{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSCA 31013 - Big Data Platforms - Course Project\n",
    "\n",
    "### B2B: Iowa Liquor Sales : Clean, Transform and Feature Engineering\n",
    "### Submitted by:\n",
    "\n",
    "#saurabhs\n",
    "#dmcdonough\n",
    "#dtallarico90\n",
    "\n",
    "@uchicago.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading and Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Step one is to import the necessary packages and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "#PySpark SQL packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import upper, col\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# PySpark pipeline and feature packages\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# PySpark ML Algorithms for regression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "# Supress pandas or other warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download data, clean special characters and upload onto HDFS\n",
    "#### Below code is run on hadoop cluster to download and clean the file from the Iowa state website. \n",
    "#### NOTE: Lines have been commented since files have been downloadded on HDFS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curl https://data.iowa.gov/api/views/m3tr-qhgy/rows.csv?accessType=DOWNLOAD -o Iowa_Liquor_Sales.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curl https://data.iowa.gov/api/views/ykb6-ywnd/rows.csv?accessType=DOWNLOAD -o Iowa_Liquor_Stores.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigDataProject.ipynb\r\n",
      "catmap.csv\r\n",
      "Forecast_NoCat.csv\r\n",
      "Forecast_WithCat.csv\r\n",
      "Iowa_Liquor_Sales-clean.csv\r\n",
      "Iowa_Liquor_Sales.csv\r\n",
      "Iowa_Liquor_Stores.csv\r\n",
      "Iowa_Population.csv\r\n",
      "ProjectLiquor_DataCleanTransform_Regression_v2.ipynb\r\n",
      "ProjectLiquor_DataCleanTransform_v2.ipynb\r\n",
      "ProjectLiquor.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "#! ls /home/saurabhs/BigData/Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove special characters from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! sed -E \"s#([0-9]{2})/([0-9]{2})/([0-9]{4})#\\3-\\1-\\2#\" < Iowa_Liquor_Sales.csv | tr -d '$' > Iowa_Liquor_Sales-clean.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ls /home/saurabhs/BigData/Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8.0G\r\n",
      "drwxrwxr-x 3 saurabhs saurabhs 4.0K Mar 12 10:36 .\r\n",
      "drwxrwxr-x 7 saurabhs saurabhs 4.0K Feb 27 09:13 ..\r\n",
      "-rw-r--r-- 1 saurabhs saurabhs  64K Mar  7 16:16 BigDataProject.ipynb\r\n",
      "-rw-r--r-- 1 saurabhs saurabhs 2.9K Mar 12 10:29 catmap.csv\r\n",
      "-rw-r--r-- 1 saurabhs saurabhs 834K Mar 11 15:13 Forecast_NoCat.csv\r\n",
      "-rw-r--r-- 1 saurabhs saurabhs 4.9M Mar 11 15:13 Forecast_WithCat.csv\r\n",
      "-rw-r--r-- 1 saurabhs saurabhs 4.0G Mar  7 09:42 Iowa_Liquor_Sales-clean.csv\r\n",
      "-rw-rw-r-- 1 saurabhs saurabhs 4.0G Mar  7 09:36 Iowa_Liquor_Sales.csv\r\n",
      "-rw-r--r-- 1 saurabhs saurabhs 266K Mar  7 09:05 Iowa_Liquor_Stores.csv\r\n",
      "-rw-r--r-- 1 saurabhs saurabhs  15K Mar 12 10:29 Iowa_Population.csv\r\n",
      "drwxr-xr-x 2 saurabhs saurabhs 4.0K Mar 12 10:28 .ipynb_checkpoints\r\n",
      "-rw-r--r-- 1 saurabhs saurabhs 238K Mar 11 17:34 ProjectLiquor_DataCleanTransform_Regression_v2.ipynb\r\n",
      "-rw-r--r-- 1 saurabhs saurabhs 176K Mar 12 10:36 ProjectLiquor_DataCleanTransform_v2.ipynb\r\n",
      "-rw-r--r-- 1 saurabhs saurabhs 102K Mar  8 14:02 ProjectLiquor.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "# Check file size\n",
    "#! ls -lah /home/saurabhs/BigData/Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move clean file to hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! hdfs dfs -put -f Iowa_Liquor_Sales-clean.csv /user/saurabhs/BigData/Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! hdfs dfs -put -f Iowa_Liquor_Stores.csv /user/saurabhs/BigData/Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0\n",
      "Found 4 items\n",
      "-rw-r--r--   3 saurabhs saurabhs     853875 2019-03-11 16:43 /user/saurabhs/BigData/Project/Forecast_NoCat.csv\n",
      "-rw-r--r--   3 saurabhs saurabhs    5090776 2019-03-11 16:37 /user/saurabhs/BigData/Project/Forecast_WithCat.csv\n",
      "-rw-r--r--   3 saurabhs saurabhs 4269077843 2019-03-07 09:49 /user/saurabhs/BigData/Project/Iowa_Liquor_Sales-clean.csv\n",
      "-rw-r--r--   3 saurabhs saurabhs     271756 2019-03-07 09:50 /user/saurabhs/BigData/Project/Iowa_Liquor_Stores.csv\n"
     ]
    }
   ],
   "source": [
    "#! hdfs dfs -ls /user/saurabhs/BigData/Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Instantiate sparksession object by checking if this notebook is running locally or on RCC. Load spark dataframe and check schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook import notebookapp\n",
    "servers = list(notebookapp.list_running_servers())\n",
    "\n",
    "# Check if running local or on RCC\n",
    "if (servers[0]['hostname'] == \"localhost\"):\n",
    "    IsRCC = False\n",
    "else:\n",
    "    IsRCC = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load context objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (IsRCC):\n",
    "    spark = SparkSession.builder.appName('ProjectLiquor').getOrCreate()\n",
    "    sqlContext = SQLContext(sc) # RCC spark context\n",
    "else:\n",
    "    #create Spark session locally\n",
    "    spark = SparkSession.builder.appName('ProjectLiquor_local').getOrCreate()\n",
    "\n",
    "    #change configuration settings on Spark \n",
    "    conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '5g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '4'), ('spark.cores.max', '4'), ('spark.driver.memory','8g')])\n",
    "    sc = spark.sparkContext # Local spark context\n",
    "    sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://INFERNO-PC:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ProjectLiquor_local</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1a4cf3f17f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm configuration of spark driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.port', '59132'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.executor.memory', '5g'),\n",
       " ('spark.executor.cores', '4'),\n",
       " ('spark.cores.max', '4'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.memory', '8g'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.driver.host', 'INFERNO-PC'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.name', 'ProjectLiquor_local'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.app.id', 'local-1552427533135')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print spark configuration settings\n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load file path accordingly in case of RCC vs Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (IsRCC): \n",
    "    # Update to RCC file names\n",
    "    BD_File = '/user/saurabhs/BigData/Project/Iowa_Liquor_Sales-clean.csv'\n",
    "else:\n",
    "    #Update to local file names\n",
    "    BD_File = 'Iowa_Liquor_Sales-clean.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the file into PySpark dataframe for downstream processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "  \n",
    "df = (spark.read\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".option(\"multiLine\", \"true\")\n",
    ".option(\"delimiter\", \",\")\n",
    ".format(\"csv\")\n",
    ".load(BD_File))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repartition based on number of years of data\n",
    "df = df.repartition(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data types and schema of the loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Invoice/Item Number', 'string'),\n",
       " ('Date', 'string'),\n",
       " ('Store Number', 'int'),\n",
       " ('Store Name', 'string'),\n",
       " ('Address', 'string'),\n",
       " ('City', 'string'),\n",
       " ('Zip Code', 'string'),\n",
       " ('Store Location', 'string'),\n",
       " ('County Number', 'int'),\n",
       " ('County', 'string'),\n",
       " ('Category', 'int'),\n",
       " ('Category Name', 'string'),\n",
       " ('Vendor Number', 'int'),\n",
       " ('Vendor Name', 'string'),\n",
       " ('Item Number', 'string'),\n",
       " ('Item Description', 'string'),\n",
       " ('Pack', 'int'),\n",
       " ('Bottle Volume (ml)', 'int'),\n",
       " ('State Bottle Cost', 'double'),\n",
       " ('State Bottle Retail', 'double'),\n",
       " ('Bottles Sold', 'int'),\n",
       " ('Sale (Dollars)', 'double'),\n",
       " ('Volume Sold (Liters)', 'double'),\n",
       " ('Volume Sold (Gallons)', 'double')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it is good when the data types are as expected. this indicates no corrupted records\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Invoice/Item Number: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Store Number: integer (nullable = true)\n",
      " |-- Store Name: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zip Code: string (nullable = true)\n",
      " |-- Store Location: string (nullable = true)\n",
      " |-- County Number: integer (nullable = true)\n",
      " |-- County: string (nullable = true)\n",
      " |-- Category: integer (nullable = true)\n",
      " |-- Category Name: string (nullable = true)\n",
      " |-- Vendor Number: integer (nullable = true)\n",
      " |-- Vendor Name: string (nullable = true)\n",
      " |-- Item Number: string (nullable = true)\n",
      " |-- Item Description: string (nullable = true)\n",
      " |-- Pack: integer (nullable = true)\n",
      " |-- Bottle Volume (ml): integer (nullable = true)\n",
      " |-- State Bottle Cost: double (nullable = true)\n",
      " |-- State Bottle Retail: double (nullable = true)\n",
      " |-- Bottles Sold: integer (nullable = true)\n",
      " |-- Sale (Dollars): double (nullable = true)\n",
      " |-- Volume Sold (Liters): double (nullable = true)\n",
      " |-- Volume Sold (Gallons): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Clean and transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check null values and NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------+----------+-------+-----+--------+--------------+-------------+------+--------+-------------+-------------+-----------+-----------+----------------+----+------------------+-----------------+-------------------+------------+--------------+--------------------+---------------------+\n",
      "|Invoice/Item Number|Date|Store Number|Store Name|Address| City|Zip Code|Store Location|County Number|County|Category|Category Name|Vendor Number|Vendor Name|Item Number|Item Description|Pack|Bottle Volume (ml)|State Bottle Cost|State Bottle Retail|Bottles Sold|Sale (Dollars)|Volume Sold (Liters)|Volume Sold (Gallons)|\n",
      "+-------------------+----+------------+----------+-------+-----+--------+--------------+-------------+------+--------+-------------+-------------+-----------+-----------+----------------+----+------------------+-----------------+-------------------+------------+--------------+--------------------+---------------------+\n",
      "|                  0|   0|           0|         0|  75143|75142|   75187|         75142|       151947|151945|   13725|        21791|            4|          2|          0|               0|   0|                 0|               10|                 10|           0|            10|                   0|                    0|\n",
      "+-------------------+----+------------+----------+-------+-----+--------+--------------+-------------+------+--------+-------------+-------------+-----------+-----------+----------------+----+------------------+-----------------+-------------------+------------+--------------+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have close to 15.7M records, we may drop all NaN records but let's keep for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the zero dollars or negative transaction rows\n",
    "df=df.filter(df[\"Sale (Dollars)\"]>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the first column into invoice number and item number by reversing and then splitting since the invoice is dynamic len.\n",
    "df = df.withColumn('InvoiceItemNumClean', F.reverse(df[\"Invoice/Item Number\"]))\n",
    "df = df.withColumn('ItemNum', df[\"InvoiceItemNumClean\"].substr(1, 5))\n",
    "df = df.withColumn('InvoiceNum', F.substring(\"InvoiceItemNumClean\", 6, 20)) # Large length to take all values (Max Length is 16)\n",
    "\n",
    "#Add date columns\n",
    "df = df.withColumn('saledate', F.to_date(F.from_unixtime(F.unix_timestamp('Date', 'MM/dd/yyy'))))\n",
    "df = df.withColumn(\"salemonth\", F.month(\"saledate\"))\n",
    "df = df.withColumn(\"saleyear\", F.year(\"saledate\"))\n",
    "df = df.withColumn('dow', F.date_format(\"saledate\", 'EEEE'))\n",
    "df = df.withColumn('dow_number', F.date_format(\"saledate\", 'u'))\n",
    "df = df.withColumn(\"saleq\", F.quarter(\"saledate\"))\n",
    "\n",
    "# Clean columns for inconsistencies in case\n",
    "df = df.withColumn('City', F.upper(F.col('City')))\n",
    "df = df.withColumn('Store Name', F.upper(F.col('Store Name')))\n",
    "df = df.withColumn('Category Name', F.upper(F.col('Category Name')))\n",
    "df = df.withColumn('Vendor Name', F.upper(F.col('Vendor Name')))\n",
    "df = df.withColumn('Item Description', F.upper(F.col('Item Description')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diff of current dates vs saledate column to calc age of store\n",
    "df = df.withColumn('date_diff', F.datediff(F.to_date(F.from_unixtime(F.unix_timestamp(F.lit('03/09/2019'), 'MM/dd/yyy')))\\\n",
    "                                               , F.to_date(df.saledate)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Retail cost total volume\n",
    "df = df.withColumn(\"sumcost\", col(\"Bottles Sold\")*col(\"State Bottle Cost\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider only full year data from 2018 to 2013 (Each year calculated using 3 years of rolling data)\n",
    "df = df.filter(df[\"saleyear\"]<2019).filter(df[\"saleyear\"]>=2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create temp view for creating subtables\n",
    "df.createOrReplaceTempView(\"tempMain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering for modeling\n",
    "### 2.1 Create table sales forecast modeling - This wud be used to fit regression models.\n",
    "We need to identify all the categories each store sold in every year and then transform those as columns applicable for each store and year combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_sales = spark.sql('''\n",
    "SELECT `Store Number` as storenumber, saleyear, `Category Name` as categoryname, sum(`Sale (Dollars)`) as categorysales\n",
    "FROM tempMain\n",
    "GROUP BY `Store Number`,saleyear, `Category Name`\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------------+-----------------+\n",
      "|storenumber|saleyear|   categoryname|    categorysales|\n",
      "+-----------+--------+---------------+-----------------+\n",
      "|       2613|    2015| VODKA FLAVORED|7670.559999999999|\n",
      "|       3692|    2013| CREAM LIQUEURS|9122.109999999999|\n",
      "|       5258|    2017|IMPORTED VODKAS|           447.24|\n",
      "+-----------+--------+---------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cat_sales.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing annual sales to calculate distribution\n",
    "df_ann_sales = spark.sql('''\n",
    "SELECT `Store Number` as storenumber, saleyear, sum(`Sale (Dollars)`) as totalsales\n",
    "FROM tempMain\n",
    "GROUP BY `Store Number`,saleyear\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load category mapping file to merge to dataset (for RCC file needs to be on home directory and not HDFS)\n",
    "if(IsRCC):\n",
    "    catmap = pd.read_csv('/home/saurabhs/BigData/Project/catmap.csv')\n",
    "else:\n",
    "    catmap = pd.read_csv('catmap.csv')\n",
    "\n",
    "catmap['catname'] = catmap['catname'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to pandas to transform rows to columns\n",
    "pdf_cat_sales = df_cat_sales.toPandas()\n",
    "pdf_cat_sales = pdf_cat_sales.merge(catmap,left_on='categoryname',right_on='catname',how='left')\n",
    "\n",
    "pdf_ann_sales = df_ann_sales.toPandas()\n",
    "pdf_cat_sales = pdf_cat_sales.merge(pdf_ann_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming rows into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to columns\n",
    "pdf_cat_sales['catratio']=pdf_cat_sales['categorysales']/pdf_cat_sales['totalsales']\n",
    "\n",
    "pdf_cat_sales_pv = pd.pivot_table(pdf_cat_sales, values='catratio', index=['storenumber', 'saleyear']\\\n",
    "                               ,columns=['type'], aggfunc=np.sum, fill_value=0)\n",
    "pdf_cat_sales_rows = pd.DataFrame(pdf_cat_sales_pv.to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storenumber</th>\n",
       "      <th>saleyear</th>\n",
       "      <th>Gin</th>\n",
       "      <th>Other</th>\n",
       "      <th>Rum</th>\n",
       "      <th>Tequila</th>\n",
       "      <th>Vodka</th>\n",
       "      <th>Whiskey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2106</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.028176</td>\n",
       "      <td>0.221125</td>\n",
       "      <td>0.157904</td>\n",
       "      <td>0.058302</td>\n",
       "      <td>0.201065</td>\n",
       "      <td>0.333428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2106</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.027590</td>\n",
       "      <td>0.268574</td>\n",
       "      <td>0.117284</td>\n",
       "      <td>0.060731</td>\n",
       "      <td>0.228773</td>\n",
       "      <td>0.297048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2106</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.022929</td>\n",
       "      <td>0.217254</td>\n",
       "      <td>0.191169</td>\n",
       "      <td>0.069177</td>\n",
       "      <td>0.197990</td>\n",
       "      <td>0.301482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2106</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.027675</td>\n",
       "      <td>0.265186</td>\n",
       "      <td>0.135684</td>\n",
       "      <td>0.057878</td>\n",
       "      <td>0.193643</td>\n",
       "      <td>0.317652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2106</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.023629</td>\n",
       "      <td>0.213437</td>\n",
       "      <td>0.208394</td>\n",
       "      <td>0.079311</td>\n",
       "      <td>0.200236</td>\n",
       "      <td>0.265879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2106</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.022272</td>\n",
       "      <td>0.249634</td>\n",
       "      <td>0.153142</td>\n",
       "      <td>0.064041</td>\n",
       "      <td>0.224176</td>\n",
       "      <td>0.286581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2113</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>0.231270</td>\n",
       "      <td>0.132035</td>\n",
       "      <td>0.021374</td>\n",
       "      <td>0.241686</td>\n",
       "      <td>0.362332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2113</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.033136</td>\n",
       "      <td>0.152988</td>\n",
       "      <td>0.254053</td>\n",
       "      <td>0.039879</td>\n",
       "      <td>0.161301</td>\n",
       "      <td>0.358642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2113</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.014375</td>\n",
       "      <td>0.114436</td>\n",
       "      <td>0.222948</td>\n",
       "      <td>0.026078</td>\n",
       "      <td>0.211577</td>\n",
       "      <td>0.410586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2113</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.021860</td>\n",
       "      <td>0.131488</td>\n",
       "      <td>0.173465</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>0.199067</td>\n",
       "      <td>0.459379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2113</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.025193</td>\n",
       "      <td>0.087575</td>\n",
       "      <td>0.187282</td>\n",
       "      <td>0.041153</td>\n",
       "      <td>0.278598</td>\n",
       "      <td>0.380198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2113</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.135790</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>0.077911</td>\n",
       "      <td>0.207631</td>\n",
       "      <td>0.339412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    storenumber  saleyear       Gin     Other       Rum   Tequila     Vodka  \\\n",
       "0          2106      2013  0.028176  0.221125  0.157904  0.058302  0.201065   \n",
       "1          2106      2014  0.027590  0.268574  0.117284  0.060731  0.228773   \n",
       "2          2106      2015  0.022929  0.217254  0.191169  0.069177  0.197990   \n",
       "3          2106      2016  0.027675  0.265186  0.135684  0.057878  0.193643   \n",
       "4          2106      2017  0.023629  0.213437  0.208394  0.079311  0.200236   \n",
       "5          2106      2018  0.022272  0.249634  0.153142  0.064041  0.224176   \n",
       "6          2113      2013  0.011302  0.231270  0.132035  0.021374  0.241686   \n",
       "7          2113      2014  0.033136  0.152988  0.254053  0.039879  0.161301   \n",
       "8          2113      2015  0.014375  0.114436  0.222948  0.026078  0.211577   \n",
       "9          2113      2016  0.021860  0.131488  0.173465  0.014741  0.199067   \n",
       "10         2113      2017  0.025193  0.087575  0.187282  0.041153  0.278598   \n",
       "11         2113      2018  0.011747  0.135790  0.227509  0.077911  0.207631   \n",
       "\n",
       "     Whiskey  \n",
       "0   0.333428  \n",
       "1   0.297048  \n",
       "2   0.301482  \n",
       "3   0.317652  \n",
       "4   0.265879  \n",
       "5   0.286581  \n",
       "6   0.362332  \n",
       "7   0.358642  \n",
       "8   0.410586  \n",
       "9   0.459379  \n",
       "10  0.380198  \n",
       "11  0.339412  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_cat_sales_rows.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save locally and reload into spark df (Hacked method, otherwise PySpark errors due to schema issues)\n",
    "\n",
    "if(IsRCC):\n",
    "    df_cat_sales_cols = sqlContext.createDataFrame(pdf_cat_sales_rows)\n",
    "else:\n",
    "    pdf_cat_sales_rows.to_csv(\"catsales.csv\", index=False)\n",
    "\n",
    "    df_cat_sales_cols = (spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"multiLine\", \"true\")\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .format(\"csv\")\n",
    "    .load(\"catsales.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(storenumber=2106, saleyear=2013, Gin=0.028176117185159277, Other=0.2211248486779781, Rum=0.15790388475453365, Tequila=0.0583024570020315, Vodka=0.20106516848484013, Whiskey=0.3334275238954576)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_sales_cols.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store, Year, Mark Up\n",
    "df_mkup_sales = spark.sql('''\n",
    "SELECT `Store Number`,saleyear, (sum(`Sale (Dollars)`)-sum(`sumcost`)) /sum(`sumcost`) as markup\n",
    "FROM tempMain\n",
    "WHERE saleyear between 2015 and 2018\n",
    "GROUP BY  `Store Number`,saleyear\n",
    "Order By `Store Number`,`saleyear`''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-------------------+\n",
      "|Store Number|saleyear|             markup|\n",
      "+------------+--------+-------------------+\n",
      "|        2106|    2015| 0.5008903458289726|\n",
      "|        2106|    2016|0.49699790570960534|\n",
      "|        2106|    2017| 0.4960744197023383|\n",
      "+------------+--------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_mkup_sales.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Tenure of stores\n",
    "df_tenure = spark.sql('''\n",
    "SELECT `Store Number`, max(date_diff) as days_in_business\n",
    "FROM tempMain\n",
    "Group By `Store Number`''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "|Store Number|days_in_business|\n",
      "+------------+----------------+\n",
      "|        3918|            2256|\n",
      "|        4900|            2097|\n",
      "|        4818|            2252|\n",
      "+------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tenure.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store,Year, Annual sales (current and previous year)\n",
    "df_year_sales = spark.sql('''\n",
    "SELECT Year1.`Store Number`, Year1.saleyear, Year1.Yearly_Total_Sales, \n",
    "case when Year2.Yearly_Total_Sales is null then 0 else Year2.Yearly_Total_Sales end as Last_Year_Sales\n",
    "from \n",
    "(SELECT `Store Number`,saleyear, sum(`Sale (Dollars)`) as Yearly_Total_Sales\n",
    "FROM tempMain\n",
    "WHERE saleyear between 2015 and 2018\n",
    "GROUP BY  `Store Number`, saleyear\n",
    ") as Year1\n",
    "LEFT JOIN  \n",
    "(SELECT `Store Number`,saleyear, sum(`Sale (Dollars)`) as Yearly_Total_Sales\n",
    "FROM tempMain\n",
    "WHERE saleyear between 2014 and 2017\n",
    "GROUP BY  `Store Number`, saleyear\n",
    ") as Year2\n",
    "ON Year2.`Store Number` = Year1.`Store Number` AND Year1.saleyear = (Year2.saleyear+1) \n",
    "Order By Year1.`Store Number`, Year1.saleyear\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------------+------------------+\n",
      "|Store Number|saleyear|Yearly_Total_Sales|   Last_Year_Sales|\n",
      "+------------+--------+------------------+------------------+\n",
      "|        2106|    2015|         172518.49|155672.21999999997|\n",
      "|        2106|    2016|175869.29000000004|172518.49000000002|\n",
      "|        2106|    2017|209448.04000000004|175869.29000000004|\n",
      "|        2106|    2018|216470.00000000006|         209448.04|\n",
      "|        2113|    2015|12261.899999999998|          13876.64|\n",
      "|        2113|    2016|          12990.68|           12261.9|\n",
      "|        2113|    2017|12860.230000000003|          12990.68|\n",
      "|        2113|    2018|11746.960000000001|          12860.23|\n",
      "|        2130|    2015|192385.42999999996|         120890.46|\n",
      "|        2130|    2016|         159179.85|         192385.43|\n",
      "|        2130|    2017|167556.19999999998|         159179.85|\n",
      "|        2130|    2018|         199922.26|167556.19999999998|\n",
      "+------------+--------+------------------+------------------+\n",
      "only showing top 12 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_year_sales.show(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store,Year, and (Year-1) and (Year-2) sales by quarter\n",
    "df_growth_sales = spark.sql('''\n",
    "SELECT Year1.`Store Number`, Year1.saleyear, Year1.saleq, Year1.Qtr_Sales, \n",
    "case when Year2.Qtr_Sales is null then 0 else Year2.Qtr_Sales end as Last_Year_Qtr_Sales\n",
    "from \n",
    "(SELECT `Store Number`,saleyear, saleq, sum(`Sale (Dollars)`) as Qtr_Sales\n",
    "FROM tempMain\n",
    "WHERE saleyear between 2014 and 2017\n",
    "GROUP BY  `Store Number`, saleyear, saleq\n",
    ") as Year1\n",
    "LEFT JOIN  \n",
    "(SELECT `Store Number`,saleyear, saleq, sum(`Sale (Dollars)`) as Qtr_Sales\n",
    "FROM tempMain\n",
    "WHERE saleyear between 2013 and 2016\n",
    "GROUP BY  `Store Number`, saleyear, saleq\n",
    ") as Year2\n",
    "ON Year2.`Store Number` = Year1.`Store Number` AND Year1.saleyear = (Year2.saleyear+1) AND Year1.saleq = Year2.saleq\n",
    "Order By Year1.`Store Number`, Year1.saleyear, Year1.saleq\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+------------------+-------------------+\n",
      "|Store Number|saleyear|saleq|         Qtr_Sales|Last_Year_Qtr_Sales|\n",
      "+------------+--------+-----+------------------+-------------------+\n",
      "|        2106|    2014|    1|32166.630000000005| 34423.240000000005|\n",
      "|        2106|    2014|    2| 39602.67999999999|           35657.38|\n",
      "|        2106|    2014|    3|44595.170000000006| 35792.649999999994|\n",
      "|        2106|    2014|    4|          39307.74|           38479.48|\n",
      "|        2106|    2015|    1|43174.310000000005|           32166.63|\n",
      "|        2106|    2015|    2|          43450.72|           39602.68|\n",
      "|        2106|    2015|    3|          44052.02|           44595.17|\n",
      "|        2106|    2015|    4|41841.439999999995| 39307.740000000005|\n",
      "|        2106|    2016|    1|44759.880000000005| 43174.310000000005|\n",
      "|        2106|    2016|    2|          43903.03|           43450.72|\n",
      "|        2106|    2016|    3|          39201.35|           44052.02|\n",
      "|        2106|    2016|    4|          48005.03|           41841.44|\n",
      "+------------+--------+-----+------------------+-------------------+\n",
      "only showing top 12 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_growth_sales.show(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store,Year, City\n",
    "df_city = spark.sql('''\n",
    "SELECT `Store Number`,saleyear, City\n",
    "FROM tempMain\n",
    "WHERE saleyear between 2015 and 2018\n",
    "GROUP BY  `Store Number`,saleyear,City\n",
    "Order By `Store Number`,`saleyear`,City asc''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----------+\n",
      "|Store Number|saleyear|       City|\n",
      "+------------+--------+-----------+\n",
      "|        2106|    2015|CEDAR FALLS|\n",
      "|        2106|    2016|CEDAR FALLS|\n",
      "|        2106|    2017|CEDAR FALLS|\n",
      "|        2106|    2018|CEDAR FALLS|\n",
      "|        2113|    2015|     GOWRIE|\n",
      "+------------+--------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_city.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuse population demographic data with original city dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create spark df from filename supplied / Used for merging smaller datasets with primary Big dataset\n",
    "def create_spark_dataframe(file_name):\n",
    "    \"\"\"\n",
    "    will return the spark dataframe input pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    if(IsRCC):\n",
    "        sdf = (spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"multiLine\", \"true\")\n",
    "        .option(\"delimiter\", \",\")\n",
    "        .format(\"csv\")\n",
    "        .load(file_name))\n",
    "        \n",
    "        pandas_data_frame = sdf.toPandas()        \n",
    "    else:\n",
    "        pandas_data_frame = pd.read_csv(file_name)\n",
    "        \n",
    "    \n",
    "    for col in pandas_data_frame.columns:\n",
    "        if ((pandas_data_frame[col].dtypes != np.int64) & (pandas_data_frame[col].dtypes != np.float64)):\n",
    "            pandas_data_frame[col] = pandas_data_frame[col].fillna('')\n",
    "\n",
    "    #Save locally and reload into spark df (Hacked method, otherwise PySpark errors due to schema issues)\n",
    "    \n",
    "    if(IsRCC):\n",
    "        spark_data_frame = sqlContext.createDataFrame(pandas_data_frame)\n",
    "    else:\n",
    "        pandas_data_frame.to_csv(\"temppop.csv\", index=False)\n",
    "\n",
    "        spark_data_frame = (spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"multiLine\", \"true\")\n",
    "        .option(\"delimiter\", \",\")\n",
    "        .format(\"csv\")\n",
    "        .load(\"temppop.csv\"))\n",
    "    \n",
    "    return spark_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iowa Population data file to merge to dataset (for RCC file needs to be on home directory and not HDFS)\n",
    "if(IsRCC):\n",
    "    IowaPop = create_spark_dataframe('/user/saurabhs/BigData/Project/Iowa_Population.csv')\n",
    "else:\n",
    "    IowaPop = create_spark_dataframe('Iowa_Population.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+\n",
      "|           City|Population|\n",
      "+---------------+----------+\n",
      "|     DES MOINES|   214,778|\n",
      "|   CEDAR RAPIDS|   130,330|\n",
      "|      DAVENPORT|   102,268|\n",
      "|     SIOUX CITY|    82,568|\n",
      "|      IOWA CITY|    73,415|\n",
      "|       WATERLOO|    68,146|\n",
      "|           AMES|    65,005|\n",
      "|WEST DES MOINES|    62,999|\n",
      "| COUNCIL BLUFFS|    62,317|\n",
      "|        DUBUQUE|    58,410|\n",
      "|         ANKENY|    56,237|\n",
      "|      URBANDALE|    42,222|\n",
      "|    CEDAR FALLS|    41,167|\n",
      "|         MARION|    38,014|\n",
      "|     BETTENDORF|    35,293|\n",
      "|     MASON CITY|    27,453|\n",
      "|   MARSHALLTOWN|    27,440|\n",
      "|        CLINTON|    25,892|\n",
      "|     BURLINGTON|    25,330|\n",
      "|        OTTUMWA|    24,705|\n",
      "+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IowaPop.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two dataframes together\n",
    "df_city_pop = df_city.join(IowaPop, on=['City'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+--------+----------+\n",
      "|       City|Store Number|saleyear|Population|\n",
      "+-----------+------------+--------+----------+\n",
      "|CEDAR FALLS|        2106|    2015|    41,167|\n",
      "|CEDAR FALLS|        2106|    2016|    41,167|\n",
      "|CEDAR FALLS|        2106|    2017|    41,167|\n",
      "|CEDAR FALLS|        2106|    2018|    41,167|\n",
      "|     GOWRIE|        2113|    2015|     1,009|\n",
      "|     GOWRIE|        2113|    2016|     1,009|\n",
      "|     GOWRIE|        2113|    2017|     1,009|\n",
      "|     GOWRIE|        2113|    2018|     1,009|\n",
      "|   WATERLOO|        2130|    2015|    68,146|\n",
      "|   WATERLOO|        2130|    2016|    68,146|\n",
      "|   WATERLOO|        2130|    2017|    68,146|\n",
      "|   WATERLOO|        2130|    2018|    68,146|\n",
      "|   ROCKWELL|        2152|    2015|       970|\n",
      "|   ROCKWELL|        2152|    2016|       970|\n",
      "|     WAUKON|        2178|    2015|     3,744|\n",
      "|     WAUKON|        2178|    2016|     3,744|\n",
      "|     WAUKON|        2178|    2017|     3,744|\n",
      "|     WAUKON|        2178|    2018|     3,744|\n",
      "| DES MOINES|        2190|    2015|   214,778|\n",
      "| DES MOINES|        2190|    2016|   214,778|\n",
      "+-----------+------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_city_pop.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge dataset for forecasting, create temp tables for use in spark sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create temp view for creating subtables\n",
    "#Master table\n",
    "df_year_sales.createOrReplaceTempView(\"df_year_sales\")\n",
    "\n",
    "#Tables to join\n",
    "df_cat_sales_cols.createOrReplaceTempView(\"df_cat_sales_cols\")\n",
    "df_mkup_sales.createOrReplaceTempView(\"df_mkup_sales\")\n",
    "df_tenure.createOrReplaceTempView(\"df_tenure\")\n",
    "df_growth_sales.createOrReplaceTempView(\"df_growth_sales\")\n",
    "df_city_pop.createOrReplaceTempView(\"df_city_pop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create QoQ growth columns by transforming from rows into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_growth_sales = df_growth_sales.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Number</th>\n",
       "      <th>saleyear</th>\n",
       "      <th>saleq</th>\n",
       "      <th>Qtr_Sales</th>\n",
       "      <th>Last_Year_Qtr_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2106</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>32166.63</td>\n",
       "      <td>34423.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2106</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>39602.68</td>\n",
       "      <td>35657.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2106</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>44595.17</td>\n",
       "      <td>35792.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2106</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>39307.74</td>\n",
       "      <td>38479.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2106</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>43174.31</td>\n",
       "      <td>32166.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store Number  saleyear  saleq  Qtr_Sales  Last_Year_Qtr_Sales\n",
       "0          2106      2014      1   32166.63             34423.24\n",
       "1          2106      2014      2   39602.68             35657.38\n",
       "2          2106      2014      3   44595.17             35792.65\n",
       "3          2106      2014      4   39307.74             38479.48\n",
       "4          2106      2015      1   43174.31             32166.63"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_growth_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_growth_sales['Growth'] = pdf_growth_sales.apply(lambda x: ((x['Qtr_Sales']-x['Last_Year_Qtr_Sales'])\\\n",
    "                                                               /x['Last_Year_Qtr_Sales']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Number</th>\n",
       "      <th>saleyear</th>\n",
       "      <th>saleq</th>\n",
       "      <th>Qtr_Sales</th>\n",
       "      <th>Last_Year_Qtr_Sales</th>\n",
       "      <th>Growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2106</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>32166.63</td>\n",
       "      <td>34423.24</td>\n",
       "      <td>-0.065555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2106</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>39602.68</td>\n",
       "      <td>35657.38</td>\n",
       "      <td>0.110645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2106</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>44595.17</td>\n",
       "      <td>35792.65</td>\n",
       "      <td>0.245931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2106</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>39307.74</td>\n",
       "      <td>38479.48</td>\n",
       "      <td>0.021525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2106</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>43174.31</td>\n",
       "      <td>32166.63</td>\n",
       "      <td>0.342208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store Number  saleyear  saleq  Qtr_Sales  Last_Year_Qtr_Sales    Growth\n",
       "0          2106      2014      1   32166.63             34423.24 -0.065555\n",
       "1          2106      2014      2   39602.68             35657.38  0.110645\n",
       "2          2106      2014      3   44595.17             35792.65  0.245931\n",
       "3          2106      2014      4   39307.74             38479.48  0.021525\n",
       "4          2106      2015      1   43174.31             32166.63  0.342208"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_growth_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_growth_sales_pv = pd.pivot_table(pdf_growth_sales, values='Growth',\\\n",
    "                                     index=['Store Number', 'saleyear'],columns=['saleq'],  fill_value=0)#aggfunc=np.sum,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Number</th>\n",
       "      <th>saleyear</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2106</td>\n",
       "      <td>2014</td>\n",
       "      <td>-0.065555</td>\n",
       "      <td>0.110645</td>\n",
       "      <td>0.245931</td>\n",
       "      <td>0.021525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2106</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.342208</td>\n",
       "      <td>0.097166</td>\n",
       "      <td>-0.012180</td>\n",
       "      <td>0.064458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2106</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.036725</td>\n",
       "      <td>0.010410</td>\n",
       "      <td>-0.110112</td>\n",
       "      <td>0.147308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2106</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.143686</td>\n",
       "      <td>0.246036</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.335867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2113</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.725774</td>\n",
       "      <td>0.189934</td>\n",
       "      <td>0.344151</td>\n",
       "      <td>-0.272514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store Number  saleyear         1         2         3         4\n",
       "0          2106      2014 -0.065555  0.110645  0.245931  0.021525\n",
       "1          2106      2015  0.342208  0.097166 -0.012180  0.064458\n",
       "2          2106      2016  0.036725  0.010410 -0.110112  0.147308\n",
       "3          2106      2017  0.143686  0.246036  0.005673  0.335867\n",
       "4          2113      2014  0.725774  0.189934  0.344151 -0.272514"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_growth_sales_rows = pd.DataFrame(pdf_growth_sales_pv.to_records())\n",
    "\n",
    "pdf_growth_sales_rows = pdf_growth_sales_rows.replace([np.inf, -np.inf], 0)\n",
    "pdf_growth_sales_rows = pdf_growth_sales_rows.fillna(0)\n",
    "\n",
    "pdf_growth_sales_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save locally and reload into spark df (Hacked method, otherwise PySpark errors due to schema issues)\n",
    "\n",
    "if(IsRCC):\n",
    "    df_growth_sales_QoQ = sqlContext.createDataFrame(pdf_growth_sales_rows)\n",
    "else:\n",
    "    pdf_growth_sales_rows.to_csv(\"growthsales.csv\", index=False)\n",
    "\n",
    "    df_growth_sales_QoQ = (spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"multiLine\", \"true\")\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .format(\"csv\")\n",
    "    .load(\"growthsales.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Store Number|saleyear|                   1|                   2|                   3|                   4|\n",
      "+------------+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|        2106|    2014|-0.06555484027651087| 0.11064469683414754| 0.24593093833510546| 0.02152471914901123|\n",
      "|        2106|    2015| 0.34220805847550717| 0.09716615138167418|-0.01217957011936...| 0.06445804312331337|\n",
      "|        2106|    2016|0.036724848642630294|0.010409723935529669|-0.11011231721042528| 0.14730826663709462|\n",
      "|        2106|    2017| 0.14368581863937066| 0.24603586586165047|0.005672763820633847| 0.33586667897093286|\n",
      "|        2113|    2014|  0.7257740165067664| 0.18993371152974028| 0.34415121255349496|-0.27251363339490564|\n",
      "|        2113|    2015|  0.5058849709696343| -0.2052626774384956| -0.3481736977093835|-0.21607241703133132|\n",
      "|        2113|    2016|0.041876798491080884|-0.20353034418989335| 0.32990963610214097| 0.19400054099817668|\n",
      "|        2113|    2017|-0.15301477926518886| 0.34949037535918887| 0.05699011395982343|-0.19831236042991268|\n",
      "+------------+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_growth_sales_QoQ.show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_growth_sales_QoQ.createOrReplaceTempView(\"df_growth_sales_QoQ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Merge dataframes into main dataframe with all features for processing in models\n",
    "Print columns for helping join the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_year_sales [('Store Number', 'int'), ('saleyear', 'int'), ('Yearly_Total_Sales', 'double'), ('Last_Year_Sales', 'double')]\n",
      "df_mkup_sales [('Store Number', 'int'), ('saleyear', 'int'), ('markup', 'double')]\n",
      "df_tenure [('Store Number', 'int'), ('days_in_business', 'int')]\n",
      "df_growth_sales [('Store Number', 'int'), ('saleyear', 'int'), ('saleq', 'int'), ('Qtr_Sales', 'double'), ('Last_Year_Qtr_Sales', 'double')]\n",
      "df_city_pop [('City', 'string'), ('Store Number', 'int'), ('saleyear', 'int'), ('Population', 'string')]\n",
      "df_cat_sales_cols [('storenumber', 'int'), ('saleyear', 'int'), ('Gin', 'double'), ('Other', 'double'), ('Rum', 'double'), ('Tequila', 'double'), ('Vodka', 'double'), ('Whiskey', 'double')]\n",
      "df_growth_sales_QoQ [('Store Number', 'int'), ('saleyear', 'int'), ('1', 'double'), ('2', 'double'), ('3', 'double'), ('4', 'double')]\n"
     ]
    }
   ],
   "source": [
    "print(\"df_year_sales\",df_year_sales.dtypes)\n",
    "print(\"df_mkup_sales\",df_mkup_sales.dtypes)\n",
    "print(\"df_tenure\",df_tenure.dtypes)\n",
    "print(\"df_growth_sales\",df_growth_sales.dtypes)\n",
    "print(\"df_city_pop\",df_city_pop.dtypes)\n",
    "print(\"df_cat_sales_cols\",df_cat_sales_cols.dtypes)\n",
    "print(\"df_growth_sales_QoQ\",df_growth_sales_QoQ.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+--------+----------+\n",
      "|       City|Store Number|saleyear|Population|\n",
      "+-----------+------------+--------+----------+\n",
      "|CEDAR FALLS|        2106|    2015|    41,167|\n",
      "|CEDAR FALLS|        2106|    2016|    41,167|\n",
      "|CEDAR FALLS|        2106|    2017|    41,167|\n",
      "|CEDAR FALLS|        2106|    2018|    41,167|\n",
      "|     GOWRIE|        2113|    2015|     1,009|\n",
      "|     GOWRIE|        2113|    2016|     1,009|\n",
      "|     GOWRIE|        2113|    2017|     1,009|\n",
      "|     GOWRIE|        2113|    2018|     1,009|\n",
      "|   WATERLOO|        2130|    2015|    68,146|\n",
      "|   WATERLOO|        2130|    2016|    68,146|\n",
      "|   WATERLOO|        2130|    2017|    68,146|\n",
      "|   WATERLOO|        2130|    2018|    68,146|\n",
      "|   ROCKWELL|        2152|    2015|       970|\n",
      "|   ROCKWELL|        2152|    2016|       970|\n",
      "|     WAUKON|        2178|    2015|     3,744|\n",
      "|     WAUKON|        2178|    2016|     3,744|\n",
      "|     WAUKON|        2178|    2017|     3,744|\n",
      "|     WAUKON|        2178|    2018|     3,744|\n",
      "| DES MOINES|        2190|    2015|   214,778|\n",
      "| DES MOINES|        2190|    2016|   214,778|\n",
      "+-----------+------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_city_pop.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create forecasting table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasting = spark.sql('''\n",
    "SELECT Year1.`Store Number`, Year1.saleyear, Year1.Yearly_Total_Sales, Year1.Last_Year_Sales, \n",
    "case when MkUp.markup is null then 0 else MkUp.markup end as Markup,\n",
    "case when Tenure.days_in_business is null then 0 else Tenure.days_in_business  end as Tenure_days,\n",
    "case when QoQ.`1` is null then 0 else QoQ.`1`  end as Q1_QoQ_Sales,\n",
    "case when QoQ.`2` is null then 0 else QoQ.`2`  end as Q2_QoQ_Sales,\n",
    "case when QoQ.`3` is null then 0 else QoQ.`3`  end as Q3_QoQ_Sales,\n",
    "case when QoQ.`4` is null then 0 else QoQ.`4`  end as Q4_QoQ_Sales, \n",
    "case when df_city_pop.City is null then '' else df_city_pop.City end as City,\n",
    "case when df_city_pop.Population is null then '' else df_city_pop.Population end as CityPop\n",
    "from \n",
    "df_year_sales as Year1\n",
    "LEFT JOIN df_mkup_sales as MkUp\n",
    "ON MkUp.`Store Number` = Year1.`Store Number` AND MkUp.saleyear = Year1.saleyear\n",
    "LEFT JOIN df_tenure as Tenure\n",
    "ON Tenure.`Store Number` = Year1.`Store Number`\n",
    "LEFT JOIN df_growth_sales_QoQ as QoQ\n",
    "ON QoQ.`Store Number` = Year1.`Store Number` AND (QoQ.saleyear+1) = Year1.saleyear\n",
    "LEFT JOIN df_city_pop \n",
    "ON df_city_pop.`Store Number` = Year1.`Store Number` AND df_city_pop.saleyear = Year1.saleyear\n",
    "Order By Year1.`Store Number`, Year1.saleyear\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------------+------------------+-------------------+-----------+--------------------+--------------------+--------------------+--------------------+-----------+-------+\n",
      "|Store Number|saleyear|Yearly_Total_Sales|   Last_Year_Sales|             Markup|Tenure_days|        Q1_QoQ_Sales|        Q2_QoQ_Sales|        Q3_QoQ_Sales|        Q4_QoQ_Sales|       City|CityPop|\n",
      "+------------+--------+------------------+------------------+-------------------+-----------+--------------------+--------------------+--------------------+--------------------+-----------+-------+\n",
      "|        2106|    2015|         172518.49|155672.21999999997| 0.5008903458289726|       2256|-0.06555484027651087| 0.11064469683414754| 0.24593093833510546| 0.02152471914901123|CEDAR FALLS| 41,167|\n",
      "|        2106|    2016|175869.29000000004|172518.49000000002|0.49699790570960534|       2256| 0.34220805847550717| 0.09716615138167418|-0.01217957011936...| 0.06445804312331337|CEDAR FALLS| 41,167|\n",
      "|        2106|    2017|209448.04000000004|175869.29000000004| 0.4960744197023383|       2256|0.036724848642630294|0.010409723935529669|-0.11011231721042528| 0.14730826663709462|CEDAR FALLS| 41,167|\n",
      "|        2106|    2018|216470.00000000006|         209448.04|0.49837450558036733|       2256| 0.14368581863937066| 0.24603586586165047|0.005672763820633847| 0.33586667897093286|CEDAR FALLS| 41,167|\n",
      "|        2113|    2015|12261.899999999998|          13876.64| 0.5015319130177097|       2250|  0.7257740165067664| 0.18993371152974028| 0.34415121255349496|-0.27251363339490564|     GOWRIE|  1,009|\n",
      "|        2113|    2016|          12990.68|           12261.9|  0.536558478425435|       2250|  0.5058849709696343| -0.2052626774384956| -0.3481736977093835|-0.21607241703133132|     GOWRIE|  1,009|\n",
      "|        2113|    2017|12860.230000000003|          12990.68| 0.4902290925524642|       2250|0.041876798491080884|-0.20353034418989335| 0.32990963610214097| 0.19400054099817668|     GOWRIE|  1,009|\n",
      "|        2113|    2018|11746.960000000001|          12860.23|0.49941922357211954|       2250|-0.15301477926518886| 0.34949037535918887| 0.05699011395982343|-0.19831236042991268|     GOWRIE|  1,009|\n",
      "|        2130|    2015|192385.42999999996|         120890.46|  0.500377540423575|       2256|0.025161442680563043|-0.31412101004361886|-0.27896787369539283|-0.20316094111134908|   WATERLOO| 68,146|\n",
      "|        2130|    2016|         159179.85|         192385.43|0.49453701982389997|       2256| 0.42813070967572325|  1.0304181241061316| 0.20096138188538115|  0.6577077097413532|   WATERLOO| 68,146|\n",
      "+------------+--------+------------------+------------------+-------------------+-----------+--------------------+--------------------+--------------------+--------------------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_forecasting.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecasting.createOrReplaceTempView(\"df_forecasting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge with category dataframe. We are doing it here since the number of columns are large, and we just want to pick all of them except the one's used to join the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_forecasting.join(df_cat_sales_cols, (df_forecasting[\"Store Number\"] == df_cat_sales_cols.storenumber) &\\\n",
    "                             (df_forecasting.saleyear == df_cat_sales_cols.saleyear))\\\n",
    "                                .drop(df_cat_sales_cols.saleyear).drop(df_cat_sales_cols.storenumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------------+------------------+-------------------+-----------+--------------------+--------------------+--------------------+--------------------+-----------+-------+--------------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "|Store Number|saleyear|Yearly_Total_Sales|   Last_Year_Sales|             Markup|Tenure_days|        Q1_QoQ_Sales|        Q2_QoQ_Sales|        Q3_QoQ_Sales|        Q4_QoQ_Sales|       City|CityPop|                 Gin|              Other|                Rum|             Tequila|              Vodka|            Whiskey|\n",
      "+------------+--------+------------------+------------------+-------------------+-----------+--------------------+--------------------+--------------------+--------------------+-----------+-------+--------------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "|        2106|    2015|         172518.49|155672.21999999997| 0.5008903458289726|       2256|-0.06555484027651087| 0.11064469683414754| 0.24593093833510546| 0.02152471914901123|CEDAR FALLS| 41,167|0.022928672746903814| 0.2172535825000555|0.19116855242588773| 0.06917710675533964|0.19799014007136273| 0.3014819455004504|\n",
      "|        2106|    2016|175869.29000000004|172518.49000000002|0.49699790570960534|       2256| 0.34220805847550717| 0.09716615138167418|-0.01217957011936...| 0.06445804312331337|CEDAR FALLS| 41,167|0.027674757770387318|0.26518609360394874|0.13568366597715836| 0.05787787054806441|0.19364330179532763|  0.317651819712242|\n",
      "|        2106|    2017|209448.04000000004|175869.29000000004| 0.4960744197023383|       2256|0.036724848642630294|0.010409723935529669|-0.11011231721042528| 0.14730826663709462|CEDAR FALLS| 41,167|0.023628772081132864|0.21343665951708116|0.20839421557728588| 0.07931103103184922|0.20023591531341134|0.26587863987650584|\n",
      "|        2106|    2018|216470.00000000006|         209448.04|0.49837450558036733|       2256| 0.14368581863937066| 0.24603586586165047|0.005672763820633847| 0.33586667897093286|CEDAR FALLS| 41,167|0.022272231718020973|0.24963385226590284|0.15314214440800106| 0.06404079087171431|0.22417623689194804|0.28658146625398434|\n",
      "|        2113|    2015|12261.899999999998|          13876.64| 0.5015319130177097|       2250|  0.7257740165067664| 0.18993371152974028| 0.34415121255349496|-0.27251363339490564|     GOWRIE|  1,009|0.014374607524119426|0.11443577259641655| 0.2229483195915804|0.026078340224598144|  0.211577324884398|0.41058563517888746|\n",
      "+------------+--------+------------------+------------------+-------------------+-----------+--------------------+--------------------+--------------------+--------------------+-----------+-------+--------------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check shapes of both dataframes before writing to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Forecast only:', 6088, 12)\n"
     ]
    }
   ],
   "source": [
    "print((\"Forecast only:\", df_forecasting.count(), len(df_forecasting.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Forecast with categories:', 6088, 18)\n"
     ]
    }
   ],
   "source": [
    "print((\"Forecast with categories:\", df_final.count(), len(df_final.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct datatypes and drop columns which are not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Store Number', 'int'),\n",
       " ('saleyear', 'int'),\n",
       " ('Yearly_Total_Sales', 'double'),\n",
       " ('Last_Year_Sales', 'double'),\n",
       " ('Markup', 'double'),\n",
       " ('Tenure_days', 'int'),\n",
       " ('Q1_QoQ_Sales', 'double'),\n",
       " ('Q2_QoQ_Sales', 'double'),\n",
       " ('Q3_QoQ_Sales', 'double'),\n",
       " ('Q4_QoQ_Sales', 'double'),\n",
       " ('City', 'string'),\n",
       " ('CityPop', 'string'),\n",
       " ('Gin', 'double'),\n",
       " ('Other', 'double'),\n",
       " ('Rum', 'double'),\n",
       " ('Tequila', 'double'),\n",
       " ('Vodka', 'double'),\n",
       " ('Whiskey', 'double')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct column datatypes\n",
    "df_final = df_final.withColumn(\"CityPop\", F.regexp_replace(F.col(\"CityPop\"), \"[\\$#,]\", \"\"))\n",
    "df_final = df_final.withColumn(\"CityPop\", df_final.CityPop.cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Store Number', 'int'),\n",
       " ('saleyear', 'int'),\n",
       " ('Yearly_Total_Sales', 'double'),\n",
       " ('Last_Year_Sales', 'double'),\n",
       " ('Markup', 'double'),\n",
       " ('Tenure_days', 'int'),\n",
       " ('Q1_QoQ_Sales', 'double'),\n",
       " ('Q2_QoQ_Sales', 'double'),\n",
       " ('Q3_QoQ_Sales', 'double'),\n",
       " ('Q4_QoQ_Sales', 'double'),\n",
       " ('City', 'string'),\n",
       " ('CityPop', 'double'),\n",
       " ('Gin', 'double'),\n",
       " ('Other', 'double'),\n",
       " ('Rum', 'double'),\n",
       " ('Tequila', 'double'),\n",
       " ('Vodka', 'double'),\n",
       " ('Whiskey', 'double')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Store Number: integer (nullable = true)\n",
      " |-- saleyear: integer (nullable = true)\n",
      " |-- Yearly_Total_Sales: double (nullable = true)\n",
      " |-- Last_Year_Sales: double (nullable = true)\n",
      " |-- Markup: double (nullable = true)\n",
      " |-- Tenure_days: integer (nullable = true)\n",
      " |-- Q1_QoQ_Sales: double (nullable = true)\n",
      " |-- Q2_QoQ_Sales: double (nullable = true)\n",
      " |-- Q3_QoQ_Sales: double (nullable = true)\n",
      " |-- Q4_QoQ_Sales: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- CityPop: double (nullable = true)\n",
      " |-- Gin: double (nullable = true)\n",
      " |-- Other: double (nullable = true)\n",
      " |-- Rum: double (nullable = true)\n",
      " |-- Tequila: double (nullable = true)\n",
      " |-- Vodka: double (nullable = true)\n",
      " |-- Whiskey: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------------+------------------+-------------------+-----------+--------------------+--------------------+--------------------+--------------------+-----------+-------+--------------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "|Store Number|saleyear|Yearly_Total_Sales|   Last_Year_Sales|             Markup|Tenure_days|        Q1_QoQ_Sales|        Q2_QoQ_Sales|        Q3_QoQ_Sales|        Q4_QoQ_Sales|       City|CityPop|                 Gin|              Other|                Rum|             Tequila|              Vodka|            Whiskey|\n",
      "+------------+--------+------------------+------------------+-------------------+-----------+--------------------+--------------------+--------------------+--------------------+-----------+-------+--------------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "|        2106|    2015|         172518.49|155672.21999999997| 0.5008903458289726|       2256|-0.06555484027651087| 0.11064469683414754| 0.24593093833510546| 0.02152471914901123|CEDAR FALLS|41167.0|0.022928672746903814| 0.2172535825000555|0.19116855242588773| 0.06917710675533964|0.19799014007136273| 0.3014819455004504|\n",
      "|        2106|    2016|175869.29000000004|172518.49000000002|0.49699790570960534|       2256| 0.34220805847550717| 0.09716615138167418|-0.01217957011936...| 0.06445804312331337|CEDAR FALLS|41167.0|0.027674757770387318|0.26518609360394874|0.13568366597715836| 0.05787787054806441|0.19364330179532763|  0.317651819712242|\n",
      "|        2106|    2017|209448.04000000004|175869.29000000004| 0.4960744197023383|       2256|0.036724848642630294|0.010409723935529669|-0.11011231721042528| 0.14730826663709462|CEDAR FALLS|41167.0|0.023628772081132864|0.21343665951708116|0.20839421557728588| 0.07931103103184922|0.20023591531341134|0.26587863987650584|\n",
      "|        2106|    2018|216470.00000000006|         209448.04|0.49837450558036733|       2256| 0.14368581863937066| 0.24603586586165047|0.005672763820633847| 0.33586667897093286|CEDAR FALLS|41167.0|0.022272231718020973|0.24963385226590284|0.15314214440800106| 0.06404079087171431|0.22417623689194804|0.28658146625398434|\n",
      "|        2113|    2015|12261.899999999998|          13876.64| 0.5015319130177097|       2250|  0.7257740165067664| 0.18993371152974028| 0.34415121255349496|-0.27251363339490564|     GOWRIE| 1009.0|0.014374607524119426|0.11443577259641655| 0.2229483195915804|0.026078340224598144|  0.211577324884398|0.41058563517888746|\n",
      "+------------+--------+------------------+------------------+-------------------+-----------+--------------------+--------------------+--------------------+--------------------+-----------+-------+--------------------+-------------------+-------------------+--------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incase we decide to query or analyze further\n",
    "df_final.createOrReplaceTempView(\"df_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Save final dataframe to disk \n",
    "#### We now have all columns as numeric and City as string, which will change to vector during modeling. Let us save this file for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to save to file, it will be saved in a folder created where the notebook is being run\n",
    "# <fileName>/part-00000\n",
    "# Rename manually to readable name\n",
    "# Pass mode=True to save to disk to avoid accidental writes\n",
    "def saveMyDf(df, fileName, mode=False):  \n",
    "    if (mode):\n",
    "        df.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveMyDf(df_final, \"LiqourSales_Forecast.csv\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continued in Notebook 2 for  Modelling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
